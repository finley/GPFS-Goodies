The "GPFS Goodies" package includes:

    brians_own_hot-add_script

        Hot delete any devices that don't have disk devices associated
        with them (stale LUNs), and hot-add any new devices.

    multipath.conf-creator

        Create and optionally deploy a multipath configuration
        appropriate for your LUNs and storage servers.

    gpfs_stanzafile-creator

        This script will auto-create a GPFS StanzaFile (written to
        STDOUT) that should be considered an example of how you can
        appropriately balance your disk devices across your NSD servers
        for best performance.  It may be used as-is in many cases.

    test_block_device_settings

        This program will summarize key block device settings that
        impact the performance when accessing your disk subsystems.  It
        makes no changes to your system, and is safe to run on live
        production systems.

    tune_block_device_settings
        
        This program will examine your environment including GPFS,
        storage servers, disk subsystems, and LUNs, to calculate best
        practice block device tuning settings.  It will create a single
        udev rules file with the tuning settings, using one entry for
        each LUN, and optionally deploy it to each participating storage
        server.


    Be sure to take a look at the HOWTO as well as other docs, examples,
    and half-baked goodies in:

        /usr/share/gpfs_goodies

 
New and Improved! 

    Now supports FlashStorage as well as SMClient compatible storage!
    (v20.8.4 and newer)

 
Download

    The latest version can be found here:
    http://snurl.com/gpfs_goodies_download

 
Example output from GPFS Goodies commands:

    gpfs_goodies

        [root@box ~]# gpfs_goodies
        
        gpfs_goodies v20.9.5
        
        Please try one of the following commands.  They're listed in the order
        of their typical use, from start to finish.  It's OK -- they're all
        safe, and won't do anything but show help information if run with either
        no arguments, or with --help or -h as an argument.
        
            brians_own_hot-add_script
        
                Hot delete any devices that don't have disk devices associated
                with them (stale LUNs), and hot-add any new devices.
        
            multipath.conf-creator
        
                Create and optionally deploy a multipath configuration
                appropriate for your LUNs and storage servers.
        
            gpfs_stanzafile-creator
        
                This script will auto-create a GPFS StanzaFile (written to
                STDOUT) that should be considered an example of how you can
                appropriately balance your disk devices across your NSD servers
                for best performance.  It may be used as-is in many cases.
        
            test_block_device_settings
        
                This program will summarize key block device settings that
                impact the performance when accessing your disk subsystems.  It
                makes no changes to your system, and is safe to run on live
                production systems.
        
            tune_block_device_settings
                
                This program will examine your environment including GPFS,
                storage servers, disk subsystems, and LUNs, to calculate best
                practice block device tuning settings.  It will create a single
                udev rules file with the tuning settings, using one entry for
                each LUN, and optionally deploy it to each participating storage
                server.
        
        
            Be sure to take a look at the HOWTO as well as other docs, examples,
            and half-baked goodies in:
        
                /usr/share/gpfs_goodies
        

 
 
Example help output from "multipath.conf-creator":
[root@box ~]# multipath.conf-creator
 
multipath.conf-creator v20.5.50
 
    Part of the "gpfs_goodies" package
 
Usage:  multipath.conf-creator [OPTION...] [--auto-detect | controller1 controller2...]
 
    Options can be abbreviated to minimum uniqueness.  For example, you could
    use "-h" or "--h" instead of "--help".
 
    --help
 
    --version
 
    --auto-detect
 
        Highly recomended!
 
        This command will use the output from "SMcli -d" to determine the list
        of controllers to use.  
        
        If you _don't_ specify this option, you'll need to specify a list of
        controllers on the command line instead:
 
          multipath.conf-creator controller1 controller2 etc...
 
 
    --deploy SERVER[,SERVER,...]
 
        Install the following files on each specified server:
        
          - /etc/multipath.conf
             The file generated by this tool.
        
          - /etc/modprobe.d/scsi_dh_alua.conf
             Reduce boot time when connected to multipath devices, and eliminate
             some harmless, but noisy SCSI errors that may be displayed. 
        
          - /var/mmfs/etc/nsddevices
             Tells GPFS to use your new multipath devices as NSD disks (and to
             not use any other devices).  Once installed, just run it as a
             script to see which devices it's choosing.
        
I'll also re-build the initrd or initramfs to include your new
multipath.conf and scsi_dh_alua.conf files.
 
 
    --out-file FILE
 
        Where FILE is the name you want to use for your shiny new
        multipath.conf file.
 
        Default:  I'll choose one for you and tell you what I've named it.
 
        Example:  --out-file /tmp/multipath.conf.test_run
 
 
    --no-blacklist
 
        Don't blacklist any disks.  By default, this tool will create a
        multipath.conf file that blacklists the local disks.  
        
        Please verify before rebooting your nodes by running 
        'multipath -v3' and examining the output for blacklisted devices.
 
 
    Currently Supported Storage Controllers include all IBM DS Storage
    Manager (SMClient) compatible controllers, and has been fully tested
    on the following models:
 
        DCS3700 DS3512 DS3524 DS3860
 
 
    Support: 
    
        This software is provided as-is, with no express or implied
        support.  However, the author would love to receive your
        patches.  Please contact Brian E. Finley <bfinley@us.ibm.com>
        with patches and/or suggestions.
 
        To request support for an additional storage controller, please
        email the output from 'lsscsi' to <bfinley@us.ibm.com>.  Emails
        that have an actual storage controller attached (or at least
        remote access to one) are likely to get the most attention. ;-)
 
 
 
-->  Make sure you specify one of "--auto-detect" or "a list of controllers".
 
Example help output from "brians_own_hot-add_script":
[root@box ~]# brians_own_hot-add_script 
 
brians_own_hot-add_script [--help|--version|--status|--yes]
 
    All options can be abbreviated to minimum uniqueness.
 
    This program will hot delete any devices that don't have disk
    devices associated with them (stale LUNs), and hot-add any new
    devices.
 
    --help
 
        Show this help output.
 
    --version
 
        Show this program's version number.
 
    --status
 
        Show the current LUN count, but don't actually do anything or
        make any changes.  This count will include all LUNs connected to
        the system, including local devices.
 
    --yes
 
        Hot delete any devices that don't have disk devices associated
        with them (stale LUNs), and hot-add any new devices.
 
        It's important to perform the hot-delete prior to the hot-add,
        as a disk that's no longer present may be still be considered as
        connected, and thus prevent detection of a new disk in that same
        position.
 
        The hot-delete function should be considered "safe", in that it
        won't remove the representation of any disk that is actually
        present and in use, but will only operate on disks that have
        already been removed.  If a disk has been re-located, it's stale 
        SCSI representation will be removed from it's old location and 
        then hot-added in it's new location.
 
        If it all in doubt, look at the code in this script, and make
        your own determination as to the impact of it's operation and/or
        try it in your test environment first.  
        
        You do have a test environment, right?
 
 
    Support: 
    
        This software is provided as-is, with no express or implied
        support.  However, the author would love to receive your
        patches.  Please contact Brian E. Finley <bfinley@us.ibm.com>
        with patches and/or suggestions.
 
 
 
SUGGESTION:  Please specify either --status or --yes.
 


Example help output from "test_block_device_settings":
[root@box ~]# test_block_device_settings 
 
test_block_device_settings v20.5
 
    Part of the "gpfs_goodies" package
 
 
This program will summarize key block device settings that impact the
performance when accessing your disk subsystems.  It makes no changes to
your system, and is safe to run on live production systems.
 
Usage:  test_block_device_settings [OPTION...]
 
    All options can be abbreviated to minimum uniqueness.
 
    --help
 
        Show this help output.
 
    --version
 
        Yup.  These are the only two options. ;-)
 
    --test
 
        Perform the test.  This should be considered a safe action.
 
 
    Support: 
    
        This software is provided as-is, with no express or implied
        support.  However, the author would love to receive your
        patches.  Please contact Brian E. Finley <bfinley@us.ibm.com>
        with patches and/or suggestions.
 
 
 
-->  Try using the "--test" option (or "-t" for short).
 
 
Example help output from "tune_block_device_settings":
[root@box ~]# tune_block_device_settings 
 
tune_block_device_settings v20.5.50
 
    Part of the "gpfs_goodies" package
 
Usage:  tune_block_device_settings [OPTION...] --out-file FILE
 
    All options can be abbreviated to minimum uniqueness.
 
    This program will examine your environment including GPFS, storage
    servers, disk subsystems, and LUNs, to calculate best practice block
    device tuning settings.  It will create a single udev rules file
    with the tuning settings, using one entry for each LUN, and
    optionally deploy it to each participating storage server.
    
    --help
 
    --version
 
    --test-run
 
        Create the rules, but don't deploy them.
 
 
    --deploy
 
        Deploy and activate the resultant udev rules file to each
        participating storage server.  Participating storage servers are
        identified by their role as an NSD server for any of the LUNs in
        active file systems.  Execute the command "mmlsnsd" for a list
        of these servers.
        
        The name of the udev rules file on the target NSD servers will
        be: /etc/udev/rules.d/99-ibm-storage.rules
 
 
    --out-file FILE
 
        The name of your resultant udev rules file.  This file can be
        given any name you like.  
 
        If you also use the --deploy option, this file will be deployed
        to your storage servers with the name of /etc/udev/rules.d/99-ibm-storage.rules.
 
        Example:  --out-file /tmp/my_shiny_new_udev_rules_file.conf
 
        Default:  I'll choose one for you and tell you what I've named it.
 
 
    Support: 
    
        This software is provided as-is, with no express or implied
        support.  However, the author would love to receive your
        patches.  Please contact Brian E. Finley <bfinley@us.ibm.com>
        with patches and/or suggestions.
 
 
-->  Try either "--deploy" or "--test-run"
